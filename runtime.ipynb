{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic label spreading\n",
    "\n",
    "Here, we set up the experiment, i.e. we specify for which hyperparameters the prob. label spreading should be conducted and run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T13:50:46.026409Z",
     "iopub.status.busy": "2024-08-15T13:50:46.025709Z",
     "iopub.status.idle": "2024-08-15T13:50:47.309029Z",
     "shell.execute_reply": "2024-08-15T13:50:47.307937Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scripts.plot import *\n",
    "from scripts.baseline_prob_label_spreading import *\n",
    "from scripts.probabilistic_label_spreading_print_runtime import prob_label_spreading\n",
    "\n",
    "plot_params = set_plot_layout(path_to_latex = '/home/jklees/texlive/bin/x86_64-linux') # set plot layout (optional)C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix parameters\n",
    "k = 20\n",
    "alpha = 0.9\n",
    "n_samples = 1000 # we provide 1000 feedbacks i.e., the linear system needs to be solved 1000 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Moons: 1000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"TwoMoons\" # \"EMNIST\", \"TinyImageNet\"\n",
    "path_to_dataset = \"data/prob_data/\"+ dataset_name + \"/\" + dataset_name + \".pkl\"\n",
    "\n",
    "df = pd.read_pickle(path_to_dataset)\n",
    "\n",
    "classes = list(set(df[\"label\"]))\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spreading time: 0.82 s\n"
     ]
    }
   ],
   "source": [
    "n_data = \"all\"\n",
    "data_space = \"feature\"\n",
    "prob_label_column = \"prob_label\" #  \n",
    "\n",
    "results, processed_data, time_spread = prob_label_spreading(dataset_name, df, data_space, prob_label_column, n_data, k, alpha, n_samples)\n",
    "print(f\"spreading time: {time_spread:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10-H 10,000 Data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T13:50:47.313544Z",
     "iopub.status.busy": "2024-08-15T13:50:47.313160Z",
     "iopub.status.idle": "2024-08-15T13:50:58.811317Z",
     "shell.execute_reply": "2024-08-15T13:50:58.810651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"CIFAR10-H\" \n",
    "path_to_dataset = \"data/prob_data/\"+ dataset_name + \"/\" + dataset_name + \".pkl\"\n",
    "\n",
    "df = pd.read_pickle(path_to_dataset)\n",
    "\n",
    "classes = list(set(df[\"label\"]))\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spreading time: 2.86 s\n"
     ]
    }
   ],
   "source": [
    "n_data = \"all\"\n",
    "data_space = \"CLIP_UMAP_20\"\n",
    "prob_label_column = \"prob_label\" #  \n",
    "\n",
    "results, processed_data, time_spread = prob_label_spreading(dataset_name, df, data_space, prob_label_column, n_data, k, alpha, n_samples)\n",
    "print(f\"spreading time: {time_spread:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiny ImageNet 100,000 Data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"TinyImageNet\" \n",
    "path_to_dataset = \"data/prob_data/\"+ dataset_name + \"/\" + dataset_name + \".pkl\"\n",
    "\n",
    "df = pd.read_pickle(path_to_dataset)\n",
    "\n",
    "classes = list(set(df[\"label\"]))\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spreading time: 11.82 s\n"
     ]
    }
   ],
   "source": [
    "n_data = \"all\"\n",
    "data_space = \"CLIP_UMAP_20\"\n",
    "prob_label_column = \"prob_label_effnetb0\" #  \n",
    "\n",
    "results, processed_data, time_spread = prob_label_spreading(dataset_name, df, data_space, prob_label_column, n_data, k, alpha, n_samples)\n",
    "print(f\"spreading time: {time_spread:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEMNIST (Augmented EMNIST-digits) 1,000,000 Data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"EEMNIST\" \n",
    "# path_to_dataset = \"data/prob_data/\"+ dataset_name + \"/\" + dataset_name + \".pkl\"\n",
    "path_to_dataset = \"/home/jklees/backup_prob_data/\"+ dataset_name + \"/\" + dataset_name + \".pkl\"\n",
    "\n",
    "\n",
    "df = pd.read_pickle(path_to_dataset)\n",
    "\n",
    "classes = list(set(df[\"label\"]))\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the relevant parts of the data for this experiment to reduce memory consumption\n",
    "data_spaces = [data_space]\n",
    "prob_label_columns = [prob_label_column]\n",
    "\n",
    "if all(col in df.columns for col in data_spaces):\n",
    "    columns = data_spaces + [\"label\"] + prob_label_columns\n",
    "    dff = df[columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jklees/prob_label_spreading/scripts/probabilistic_label_spreading_print_runtime.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"prediction\"] = [x.argmax() for x in spreaded_info]\n",
      "/home/jklees/prob_label_spreading/scripts/probabilistic_label_spreading_print_runtime.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['trials'] = trials\n",
      "/home/jklees/prob_label_spreading/scripts/probabilistic_label_spreading_print_runtime.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"p_hat\"] = [ (spreaded_info[i] + ((1e-4)/len(classes))) /(trials[i] + 1e-4) for i in range(len(trials))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spreading time: 260.26 s\n"
     ]
    }
   ],
   "source": [
    "n_data = \"all\"\n",
    "data_space = \"CLIP_UMAP_20\"\n",
    "prob_label_column = \"prob_label_effnetb0\" #  \n",
    "\n",
    "results, processed_data, time_spread = prob_label_spreading(dataset_name, dff, data_space, prob_label_column, n_data, k, alpha, n_samples)\n",
    "print(f\"spreading time: {time_spread:.2f} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amgxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
